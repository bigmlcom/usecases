{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting System Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "In this Jupyter notebook, we will examine sensory dataset from Nasa where we will create a model in order to predict system failure. This notebook can be generalized to any sensory driven data, such as manufacturing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules\n",
    "<ul>\n",
    "<li>You will first need to install a number of modules in order to follow along with this notebook. \n",
    "<li>Most of these packages, such as numpy and pandas, are available using <a href=\"https://conda.io/docs/user-guide/install/index.html\">Anaconda</a>. \n",
    "<li>For the machine learning pipeline, we will be making use of the <a href=\"https://bigml.readthedocs.io/en/latest/\">BigML Python bindings</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save our BigML Username and Api Key to our environment to access the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BIGML_USERNAME'] = \"ALANTURING\"\n",
    "os.environ['BIGML_API_KEY'] = \"c987d2d9e24f32792ae14856ce79da6a478d9e79\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat our main API object that all the main functions will utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "api = BigML(project=\"project/5b61a23d2a83473377000457\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "Data sets consists of multiple multivariate time series. Each time series is from a different engine ñ i.e., the data can be considered to be from a fleet of engines of the same type. Each engine starts with different degrees of initial wear and manufacturing variation which is unknown to the user. This wear and variation is considered normal, i.e., it is not considered a fault condition. There are three operational settings that have a substantial effect on engine performance. These settings are also included in the data. The data is contaminated with sensor noise.\n",
    "\n",
    "The engine is operating normally at the start of each time series, and develops a fault at some point during the series. In the training set, the fault grows in magnitude until system failure. \n",
    "The data are provided with 26 columns of numbers. Each row is a snapshot of data taken during a single operational cycle, each column is a different variable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note: Even though the data is presented as a time series, we will be using each row of the time series as an individual instance when modeling. We will add two new fields that use the 5 previous rows of an instance, but otherwise the order is not sustained. This proves to simplify the workflow and not substantially affect error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download txt train files into BigML. When creating a dataset in BigML, data can be presented in many forms and is not specific to CSV. We will use this to convert our txt files into CSVs using BigML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data to BigML\n",
    "In order to start a BigML workflow, a source object has to be created. The API function that creates a source is <code>create_source</code>. The method's inputs will be a file path to the txt file it will be converting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001_source = api.create_source(\"CMAPSSData/train_FD001.txt\")\n",
    "train_FD002_source = api.create_source(\"CMAPSSData/train_FD002.txt\")\n",
    "train_FD003_source = api.create_source(\"CMAPSSData/train_FD003.txt\")\n",
    "train_FD004_source = api.create_source(\"CMAPSSData/train_FD004.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigML's <code>ok</code> method is called in order to assure that an object is created and will wait if it is not done being completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.ok(train_FD001_source)\n",
    "api.ok(train_FD002_source)\n",
    "api.ok(train_FD003_source)\n",
    "api.ok(train_FD004_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Dataset\n",
    "BigML will use the newly created source to create datasets which will enable the API to perform many more operations. In order to create a dataset, the API calls the function <code>create_dataset</code>. The method will take the source created by the API as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001_origin_dataset = api.create_dataset(train_FD001_source)\n",
    "train_FD002_origin_dataset = api.create_dataset(train_FD002_source)\n",
    "train_FD003_origin_dataset = api.create_dataset(train_FD003_source)\n",
    "train_FD004_origin_dataset = api.create_dataset(train_FD004_source)\n",
    "\n",
    "api.ok(train_FD001_origin_dataset)\n",
    "api.ok(train_FD002_origin_dataset)\n",
    "api.ok(train_FD003_origin_dataset)\n",
    "api.ok(train_FD004_origin_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Datasets as CSVs\n",
    "BigML allows for the download of their dataset objects. In order to download a dataset as a CSV, the API calls the function <code>download_dataset</code>. The method will take the dataset created by the API and a file path as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CMAPSSData/train_FD004.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.download_dataset(train_FD001_origin_dataset,\n",
    "    filename='CMAPSSData/train_FD001.csv')\n",
    "\n",
    "api.download_dataset(train_FD002_origin_dataset,\n",
    "    filename='CMAPSSData/train_FD002.csv')\n",
    "\n",
    "api.download_dataset(train_FD003_origin_dataset,\n",
    "    filename='CMAPSSData/train_FD003.csv')\n",
    "\n",
    "api.download_dataset(train_FD004_origin_dataset,\n",
    "    filename='CMAPSSData/train_FD004.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have now converted the text files to CSV formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Newly created CSV files into Notebook as Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001 = pd.read_csv('CMAPSSData/train_FD001.csv')\n",
    "train_FD002 = pd.read_csv('CMAPSSData/train_FD002.csv')\n",
    "train_FD003 = pd.read_csv('CMAPSSData/train_FD003.csv')\n",
    "train_FD004 = pd.read_csv('CMAPSSData/train_FD004.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [train_FD001,train_FD002,train_FD003,train_FD004]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example how the dataframes are presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field1</th>\n",
       "      <th>field2</th>\n",
       "      <th>field3</th>\n",
       "      <th>field4</th>\n",
       "      <th>field5</th>\n",
       "      <th>field6</th>\n",
       "      <th>field7</th>\n",
       "      <th>field8</th>\n",
       "      <th>field9</th>\n",
       "      <th>field10</th>\n",
       "      <th>...</th>\n",
       "      <th>field19</th>\n",
       "      <th>field20</th>\n",
       "      <th>field21</th>\n",
       "      <th>field22</th>\n",
       "      <th>field23</th>\n",
       "      <th>field24</th>\n",
       "      <th>field25</th>\n",
       "      <th>field26</th>\n",
       "      <th>field27</th>\n",
       "      <th>field28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   field1  field2  field3  field4  field5  field6  field7   field8   field9  \\\n",
       "0       1       1 -0.0007 -0.0004     100  518.67  641.82  1589.70  1400.60   \n",
       "1       1       2  0.0019 -0.0003     100  518.67  642.15  1591.82  1403.14   \n",
       "\n",
       "   field10   ...     field19  field20  field21  field22  field23  field24  \\\n",
       "0    14.62   ...     8138.62   8.4195     0.03      392     2388      100   \n",
       "1    14.62   ...     8131.49   8.4318     0.03      392     2388      100   \n",
       "\n",
       "   field25  field26  field27  field28  \n",
       "0    39.06  23.4190      NaN      NaN  \n",
       "1    39.00  23.4236      NaN      NaN  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that the columns are not labeled since we converted a txt file, and we can also see that there are two columns with no data. This was a small error in converting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will frist drop the two unneeded columns at the end of each dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    df.drop(columns=[\"field27\",\"field28\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we were given the column names in the data folder, we will create a function to label the columns.\n",
    "<br /> 1)\tunit number\n",
    "<br /> 2)\ttime, in cycles\n",
    "<br /> 3)\toperational setting 1\n",
    "<br /> 4)\toperational setting 2\n",
    "<br /> 5)\toperational setting 3\n",
    "<br /> 6)\tsensor measurement  1\n",
    "<br /> 7)\tsensor measurement  2\n",
    "<br /> ...\n",
    "<br /> 26)\tsensor measurement  21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_columns(df):\n",
    "    df = df.rename(columns={\"field1\": \"unit_number\",\n",
    "                            \"field2\": \"time_cycles\",\n",
    "                            \"field3\": \"op_setting_1\",\n",
    "                            \"field4\": \"op_setting_2\",\n",
    "                            \"field5\": \"op_setting_3\"})\n",
    "    for i in np.arange(6,27):\n",
    "        df= df.rename(columns={\"field\"+str(i): \"sensory_measure_\"+str(i-5)})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001 = label_columns(train_FD001)\n",
    "train_FD002 = label_columns(train_FD002)\n",
    "train_FD003 = label_columns(train_FD003)\n",
    "train_FD004 = label_columns(train_FD004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensory_measure_1</th>\n",
       "      <th>sensory_measure_2</th>\n",
       "      <th>sensory_measure_3</th>\n",
       "      <th>sensory_measure_4</th>\n",
       "      <th>sensory_measure_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensory_measure_12</th>\n",
       "      <th>sensory_measure_13</th>\n",
       "      <th>sensory_measure_14</th>\n",
       "      <th>sensory_measure_15</th>\n",
       "      <th>sensory_measure_16</th>\n",
       "      <th>sensory_measure_17</th>\n",
       "      <th>sensory_measure_18</th>\n",
       "      <th>sensory_measure_19</th>\n",
       "      <th>sensory_measure_20</th>\n",
       "      <th>sensory_measure_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n",
       "0            1            1       -0.0007       -0.0004           100   \n",
       "1            1            2        0.0019       -0.0003           100   \n",
       "\n",
       "   sensory_measure_1  sensory_measure_2  sensory_measure_3  sensory_measure_4  \\\n",
       "0             518.67             641.82            1589.70            1400.60   \n",
       "1             518.67             642.15            1591.82            1403.14   \n",
       "\n",
       "   sensory_measure_5         ...          sensory_measure_12  \\\n",
       "0              14.62         ...                      521.66   \n",
       "1              14.62         ...                      522.28   \n",
       "\n",
       "   sensory_measure_13  sensory_measure_14  sensory_measure_15  \\\n",
       "0             2388.02             8138.62              8.4195   \n",
       "1             2388.07             8131.49              8.4318   \n",
       "\n",
       "   sensory_measure_16  sensory_measure_17  sensory_measure_18  \\\n",
       "0                0.03                 392                2388   \n",
       "1                0.03                 392                2388   \n",
       "\n",
       "   sensory_measure_19  sensory_measure_20  sensory_measure_21  \n",
       "0                 100               39.06             23.4190  \n",
       "1                 100               39.00             23.4236  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will add a column of the calculated sensory data mean for the previous 5 cycles of a row. If the row is in the first five columns of a unit then it will use the mean of its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean(df):\n",
    "    grouped = df.groupby(\"unit_number\")\n",
    "    prev_5_mean = []\n",
    "    for name, group in grouped:\n",
    "            for i in np.arange(len(group)):\n",
    "                if (i-5>=0):\n",
    "                    x = np.mean(df.iloc[2:5,5:26].values)\n",
    "                    prev_5_mean = np.append(prev_5_mean,x)\n",
    "                else:\n",
    "                    x = np.mean(df.iloc[i,5:26])\n",
    "                    prev_5_mean = np.append(prev_5_mean,x)\n",
    "    df[\"prev_5_mean\"] = prev_5_mean\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001 = add_mean(train_FD001)\n",
    "train_FD002 = add_mean(train_FD002)\n",
    "train_FD003 = add_mean(train_FD003)\n",
    "train_FD004 = add_mean(train_FD004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensory_measure_1</th>\n",
       "      <th>sensory_measure_2</th>\n",
       "      <th>sensory_measure_3</th>\n",
       "      <th>sensory_measure_4</th>\n",
       "      <th>sensory_measure_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensory_measure_13</th>\n",
       "      <th>sensory_measure_14</th>\n",
       "      <th>sensory_measure_15</th>\n",
       "      <th>sensory_measure_16</th>\n",
       "      <th>sensory_measure_17</th>\n",
       "      <th>sensory_measure_18</th>\n",
       "      <th>sensory_measure_19</th>\n",
       "      <th>sensory_measure_20</th>\n",
       "      <th>sensory_measure_21</th>\n",
       "      <th>prev_5_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>1439.220405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>1439.018352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n",
       "0            1            1       -0.0007       -0.0004           100   \n",
       "1            1            2        0.0019       -0.0003           100   \n",
       "\n",
       "   sensory_measure_1  sensory_measure_2  sensory_measure_3  sensory_measure_4  \\\n",
       "0             518.67             641.82            1589.70            1400.60   \n",
       "1             518.67             642.15            1591.82            1403.14   \n",
       "\n",
       "   sensory_measure_5     ...       sensory_measure_13  sensory_measure_14  \\\n",
       "0              14.62     ...                  2388.02             8138.62   \n",
       "1              14.62     ...                  2388.07             8131.49   \n",
       "\n",
       "   sensory_measure_15  sensory_measure_16  sensory_measure_17  \\\n",
       "0              8.4195                0.03                 392   \n",
       "1              8.4318                0.03                 392   \n",
       "\n",
       "   sensory_measure_18  sensory_measure_19  sensory_measure_20  \\\n",
       "0                2388                 100               39.06   \n",
       "1                2388                 100               39.00   \n",
       "\n",
       "   sensory_measure_21  prev_5_mean  \n",
       "0             23.4190  1439.220405  \n",
       "1             23.4236  1439.018352  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will add a column of the calculated sensory data std for the previous 5 cycles of a row. If the row is in the first five columns of a unit then it will use the std of its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_std(df):\n",
    "    grouped = df.groupby(\"unit_number\")\n",
    "    prev_5_std = []\n",
    "    for name, group in grouped:\n",
    "            for i in np.arange(len(group)):\n",
    "                if (i-5>=0):\n",
    "                    x = np.std(df.iloc[2:5,5:26].values)\n",
    "                    prev_5_std = np.append(prev_5_std,x)\n",
    "                else:\n",
    "                    x = np.std(df.iloc[i,5:26])\n",
    "                    prev_5_std = np.append(prev_5_std,x)\n",
    "    df[\"prev_5_std\"] = prev_5_std\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001 = add_std(train_FD001)\n",
    "train_FD002 = add_std(train_FD002)\n",
    "train_FD003 = add_std(train_FD003)\n",
    "train_FD004 = add_std(train_FD004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensory_measure_1</th>\n",
       "      <th>sensory_measure_2</th>\n",
       "      <th>sensory_measure_3</th>\n",
       "      <th>sensory_measure_4</th>\n",
       "      <th>sensory_measure_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensory_measure_14</th>\n",
       "      <th>sensory_measure_15</th>\n",
       "      <th>sensory_measure_16</th>\n",
       "      <th>sensory_measure_17</th>\n",
       "      <th>sensory_measure_18</th>\n",
       "      <th>sensory_measure_19</th>\n",
       "      <th>sensory_measure_20</th>\n",
       "      <th>sensory_measure_21</th>\n",
       "      <th>prev_5_mean</th>\n",
       "      <th>prev_5_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>1439.220405</td>\n",
       "      <td>2464.975680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>1439.018352</td>\n",
       "      <td>2463.741491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n",
       "0            1            1       -0.0007       -0.0004           100   \n",
       "1            1            2        0.0019       -0.0003           100   \n",
       "\n",
       "   sensory_measure_1  sensory_measure_2  sensory_measure_3  sensory_measure_4  \\\n",
       "0             518.67             641.82            1589.70            1400.60   \n",
       "1             518.67             642.15            1591.82            1403.14   \n",
       "\n",
       "   sensory_measure_5     ...       sensory_measure_14  sensory_measure_15  \\\n",
       "0              14.62     ...                  8138.62              8.4195   \n",
       "1              14.62     ...                  8131.49              8.4318   \n",
       "\n",
       "   sensory_measure_16  sensory_measure_17  sensory_measure_18  \\\n",
       "0                0.03                 392                2388   \n",
       "1                0.03                 392                2388   \n",
       "\n",
       "   sensory_measure_19  sensory_measure_20  sensory_measure_21  prev_5_mean  \\\n",
       "0                 100               39.06             23.4190  1439.220405   \n",
       "1                 100               39.00             23.4236  1439.018352   \n",
       "\n",
       "    prev_5_std  \n",
       "0  2464.975680  \n",
       "1  2463.741491  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly we will want to create two different target columns.\n",
    "<li>The fist will label the remaining useful life (RUL). The RUL is the remaning number of cycles before an engine fails.\n",
    "<li> The second will label if the engine will fail in the next 30 cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_RUL(df):\n",
    "    grouped = df.groupby(\"unit_number\")\n",
    "    ser = []\n",
    "    for name, group in grouped:\n",
    "        ser = np.append(ser,list(reversed(np.arange(len(group)))))\n",
    "    df[\"RUL\"] = ser\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001 = add_RUL(train_FD001)\n",
    "train_FD002 = add_RUL(train_FD002)\n",
    "train_FD003 = add_RUL(train_FD003)\n",
    "train_FD004 = add_RUL(train_FD004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_next_30_cycles(df):\n",
    "    df[\"failure_next_30_cycles\"] = df[\"RUL\"].apply(lambda x: True if x <= 30 else False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001 = add_next_30_cycles(train_FD001)\n",
    "train_FD002 = add_next_30_cycles(train_FD002)\n",
    "train_FD003 = add_next_30_cycles(train_FD003)\n",
    "train_FD004 = add_next_30_cycles(train_FD004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensory_measure_1</th>\n",
       "      <th>sensory_measure_2</th>\n",
       "      <th>sensory_measure_3</th>\n",
       "      <th>sensory_measure_4</th>\n",
       "      <th>sensory_measure_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensory_measure_16</th>\n",
       "      <th>sensory_measure_17</th>\n",
       "      <th>sensory_measure_18</th>\n",
       "      <th>sensory_measure_19</th>\n",
       "      <th>sensory_measure_20</th>\n",
       "      <th>sensory_measure_21</th>\n",
       "      <th>prev_5_mean</th>\n",
       "      <th>prev_5_std</th>\n",
       "      <th>RUL</th>\n",
       "      <th>failure_next_30_cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>1439.220405</td>\n",
       "      <td>2464.975680</td>\n",
       "      <td>191.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>1439.018352</td>\n",
       "      <td>2463.741491</td>\n",
       "      <td>190.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  op_setting_1  op_setting_2  op_setting_3  \\\n",
       "0            1            1       -0.0007       -0.0004           100   \n",
       "1            1            2        0.0019       -0.0003           100   \n",
       "\n",
       "   sensory_measure_1  sensory_measure_2  sensory_measure_3  sensory_measure_4  \\\n",
       "0             518.67             641.82            1589.70            1400.60   \n",
       "1             518.67             642.15            1591.82            1403.14   \n",
       "\n",
       "   sensory_measure_5           ...            sensory_measure_16  \\\n",
       "0              14.62           ...                          0.03   \n",
       "1              14.62           ...                          0.03   \n",
       "\n",
       "   sensory_measure_17  sensory_measure_18  sensory_measure_19  \\\n",
       "0                 392                2388                 100   \n",
       "1                 392                2388                 100   \n",
       "\n",
       "   sensory_measure_20  sensory_measure_21  prev_5_mean   prev_5_std    RUL  \\\n",
       "0               39.06             23.4190  1439.220405  2464.975680  191.0   \n",
       "1               39.00             23.4236  1439.018352  2463.741491  190.0   \n",
       "\n",
       "   failure_next_30_cycles  \n",
       "0                   False  \n",
       "1                   False  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will combine all dataframes and convert them into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df= train_FD001.append(train_FD002).append(train_FD003).append(train_FD004)\n",
    "combined_df.to_csv('CMAPSSData/combined_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will download the newly created CSV into BigML and create our dataset using the functions discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_source = api.create_source(\"CMAPSSData/combined_df.csv\")\n",
    "api.ok(combined_df_source)\n",
    "\n",
    "combined_df_dataset = api.create_dataset(combined_df_source)\n",
    "api.ok(combined_df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split\n",
    "Since we want our data to stay in the form of BigML's datasets, the test-train split of the data will be done through BigML's API. This form will allow for the API's computations. The test-train split will be created by the function <code>create_dataset</code> mentioned before. However, it will take advantage of the more available inputs of the function. Many BigML API functions take in a dictionary with many fields as an additional input. These fields allow for much manipulation of the original function's outcome. In a test-train split, the field of sample_rate will allow for the choosing of the percentage of data being sampled. The train dataset will have out_of_bag field set to False and the test dataset will have it set to True. Since the test out_of_bag is set to True, its size will be 20% when its sample rate is 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = api.create_dataset(\n",
    "    combined_df_dataset, {\"name\": \"Engine Failure | Training\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n",
    "test_dataset = api.create_dataset(\n",
    "    combined_df_dataset, {\"name\": \"Engine Failure | Test\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\",\n",
    "                     \"out_of_bag\": True})\n",
    "api.ok(train_dataset)\n",
    "api.ok(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Models\n",
    "We will be having to select two models. One model will be for trying to predict the exact RUL, and will be trained on the “RUL” column, and the other model will be predicting True or False for if a model will fail in the next 30 cycles, and this model will be trained on the target column “failure_next_30_cycles”.\n",
    "<br>\n",
    "<br>\n",
    "Since BigML has many models for both situations, we will use BigML’s savvy function of OpitML: an optimization process for model selection and parameterization that automatically finds the best supervised model to help solve classification and regression problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) In the first use of optiml, we will exclude the field of “failure_next_30_cycles”, since we will be predicting for remaining useful life (RUL). We will do this since both columns contain similar information and would mislead the training of the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optiml_RUL = api.create_optiml(train_dataset, {\n",
    "    \"excluded_fields\": [\"failure_next_30_cycles\",\"field1\",\"unit_number\"],\n",
    "    \"objective_field\": \"RUL\"})\n",
    "\n",
    "api.ok(optiml_RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) In the second use of optiml, we will exclude the field of “RUL”, since we will be predicting for if an engine is going to fail in the next 30 cycles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optiml_next_30 = api.create_optiml(train_dataset, {\n",
    "    \"excluded_fields\": [\"RUL\",\"field1\",\"unit_number\"],\n",
    "    \"objective_field\": \"failure_next_30_cycles\",\n",
    "    \"metric\":\"max_phi\"})\n",
    "\n",
    "api.ok(optiml_next_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will choose the two best models for both situations from our OptiML object. We will choose the best model that also has the highest count, both are ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepnet': {'best': 'deepnet/5b62e270623db83244003b60', 'count': 2},\n",
       " 'ensemble': {'best': 'ensemble/5b62ded208b07e51c9009469', 'count': 14},\n",
       " 'model': {'best': 'model/5b62e273623db8324300c685', 'count': 1}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optiml_RUL[\"object\"][\"optiml\"][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUL_model = optiml_RUL[\"object\"][\"optiml\"][\"summary\"][\"ensemble\"][\"best\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepnet': {'best': 'deepnet/5b62eda18bf7d535f800c282', 'count': 2},\n",
       " 'ensemble': {'best': 'ensemble/5b62ed78623db8324801c0db', 'count': 5},\n",
       " 'logisticregression': {'best': 'logisticregression/5b62edd308b07e51d40202cf',\n",
       "  'count': 1},\n",
       " 'model': {'best': 'model/5b62edd308b07e51d40202cc', 'count': 1}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optiml_next_30[\"object\"][\"optiml\"][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_30_model = optiml_next_30[\"object\"][\"optiml\"][\"summary\"][\"ensemble\"][\"best\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After choosing our models, we will want to create an evaluation for each model and test our performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUL_evaluation = api.create_evaluation(RUL_model,test_dataset)\n",
    "api.ok(RUL_evaluation)\n",
    "\n",
    "next_30_evaluation = api.create_evaluation(next_30_model,test_dataset)\n",
    "api.ok(next_30_evaluation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first model performs fairly well, with a root means squared error of around 44. This first model is useful because it predicts the remaining life of an engine at any stage. However, if we look at the evaluation of the classification model, we can see that it performs extremely well. This is because the model can detect much better when the sensory data of an engine is starting to change from the norm. So putting the last model up for production would be useful in identifying engines that might fail and sending resources before it actually happens. This could be applied to any sensory data, such as companies that use production lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Model: \n",
      "{'mean_absolute_error': 31.362, 'mean_squared_error': 1964.06253, 'per_class_statistics': [], 'r_squared': 0.7146}\n",
      "Roots Mean Squared Error:  44.317745091554464\n"
     ]
    }
   ],
   "source": [
    "print(\"First Model: \")\n",
    "print(RUL_evaluation[\"object\"][\"result\"][\"model\"])\n",
    "print(\"Roots Mean Squared Error: \", np.sqrt(RUL_evaluation[\"object\"][\"result\"][\"model\"][\"mean_squared_error\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification model: \n",
      "Accuracy:  0.95825\n",
      "Average Recall:  0.93867\n",
      "Average Precision:  0.89692\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification model: \")\n",
    "print(\"Accuracy: \",next_30_evaluation[\"object\"][\"result\"][\"model\"]['accuracy'])\n",
    "print(\"Average Recall: \",next_30_evaluation[\"object\"][\"result\"][\"model\"]['average_recall'])\n",
    "print(\"Average Precision: \",next_30_evaluation[\"object\"][\"result\"][\"model\"]['average_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
