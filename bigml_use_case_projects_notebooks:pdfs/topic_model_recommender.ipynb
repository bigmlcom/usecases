{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Recommendation System Using BigML's Topic Model Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "In this notebook, we will build a recommendation system using BigML's Topic Modeling, more specifically, we will take advantage of the topic distributions the model includes. This workflow will build a recommendation system for any data that has a title and a description. For this specific notebook, we will use a dataset that contains movie titles and descriptions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules\n",
    "<ul>\n",
    "<li>You will first need to install a number of modules in order to follow along with this notebook. \n",
    "<li>Most of these packages, such as numpy and pandas, are available using <a href=\"https://conda.io/docs/user-guide/install/index.html\">Anaconda</a>. \n",
    "<li>For the machine learning pipeline, we will be making use of the <a href=\"https://bigml.readthedocs.io/en/latest/\">BigML Python bindings</a>.\n",
    "<li> To optimize our nearest neighbour search for our large high-dimensional topic data set, we will be using locality-sensitive hashes built from <a href=\"https://github.com/pixelogik/NearPyNearpy\">Nearpy</a>. To install Nearpy, one can use the line \"pip install NearPy\".\n",
    "<li>  To construct our distance formula that will be used in our locality-sensitive hashes, we will use entropy from scipy and Distance from Nearpy.\n",
    "<li> To retrieve our locally stored Topic Model, we will be using pystemmer.\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NearPy in /anaconda3/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: bitarray in /anaconda3/lib/python3.6/site-packages (from NearPy) (0.8.1)\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.6/site-packages (from NearPy) (1.1.0)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.6/site-packages (from NearPy) (1.14.3)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.6/site-packages (from NearPy) (0.16.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install NearPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nearpy.distances.distance import Distance\n",
    "from scipy.stats import entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save our BigML Username and Api Key to our environment to access the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BIGML_USERNAME'] = \"EFETOROS\"\n",
    "os.environ['BIGML_API_KEY'] = \"7e5fc6a649fd0f8517fc8ecf2ebd30151c5d4fb4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our main API object with the input of our project id. The project will enable us to organize and keep track of our resources created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "api = BigML(project=\"project/5b17b75c92fb560173000387\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Data\n",
    "For this system, we will be using movie meta data from imdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"data/movies_metadata.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "\n",
       "                               homepage    id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
       "1                                   NaN  8844  tt0113497                en   \n",
       "\n",
       "  original_title                                           overview  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...   \n",
       "1        Jumanji  When siblings Judy and Peter discover an encha...   \n",
       "\n",
       "     ...     release_date      revenue runtime  \\\n",
       "0    ...       1995-10-30  373554033.0    81.0   \n",
       "1    ...       1995-12-15  262797249.0   104.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "\n",
       "                                     tagline      title  video vote_average  \\\n",
       "0                                        NaN  Toy Story  False          7.7   \n",
       "1  Roll the dice and unleash the excitement!    Jumanji  False          6.9   \n",
       "\n",
       "  vote_count  \n",
       "0     5415.0  \n",
       "1     2413.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to only focus on the title and overview, since we want this workflow to be applied to more than just movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_title                                           overview\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...\n",
       "1        Jumanji  When siblings Judy and Peter discover an encha..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = movies_df[[\"original_title\",\"overview\"]]\n",
    "movies_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to export the filtered data to a CSV because BigML creates sources from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.to_csv(\"data/movies_filtered_topic_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data to BigML\n",
    "In order to start a BigML workflow, a source object has to be created. The API function that creates a source is <code>create_source</code>. The method's inputs will be a file path to the csv it will be converting. The source will be created from the csv files written by <code>to_csv</code> from before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = api.create_source(\"data/movies_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigML's <code>ok</code> method is called in order to assure that an object is created and will wait if it is not done being completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.ok(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Dataset\n",
    "BigML will use the newly created source to create datasets which will enable the API to perform many more operations. In order to create a dataset, the API calls the function <code>create_dataset</code>. The method will take the source created by the API as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = api.create_dataset(source)\n",
    "\n",
    "api.ok(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Topic Model\n",
    "BigML's API allows for the creation of many models. For this dataset, a Topic Model will be used. The BigML API will use the method <code>create_topic_model</code>. Many BigML API functions take in a dictionary with many fields as an additional input. These fields allow for much manipulation of the original function's outcome. For our Topic Model, we will want to set the number of topics to the max number, which is 64. We want to set the number of topics high because we want the movies descriptions to be represented with detail through topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5: creating a topc model\n",
    "topic_model = api.create_topic_model(dataset,{\"number_of_topics\" : 64})\n",
    "\n",
    "# waiting for the topic model to be finished\n",
    "api.ok(topic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally Storing Our Model\n",
    "BigML's API allows for the storage of models Locally by using the function <code>export</code>. The inputs of the function will include the model id that is retrieved from the model object, as well as a json path, since the models are stored as .json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movies_topic_model.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_id = topic_model[\"object\"][\"resource\"]\n",
    "api.export(topic_model_id,\n",
    "           filename=\"movies_topic_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Batch Topic Distribution\n",
    "BigML's API allows for the creation of a batch distribution by using the function <code>create_batch_topic_distribution</code>. This step is what is at the core of our recommendation system. We will create a topic distribution with our original dataset. Every instance will have a probability of it being obtained in a topic, for all 64 topic that we have chosen to be in our model. In a sense, these probabilities give each movie a unique DNA that will help us in finding other similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_topic_distribution = api.create_batch_topic_distribution( \\\n",
    "    topic_model, dataset)\n",
    "api.ok(batch_topic_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the batch topic distributions dataset as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/distribution_predictions.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.download_batch_topic_distribution( \\\n",
    "    batch_topic_distribution, filename=('data/distribution_predictions.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read our new distribution CSV into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = pd.read_csv('data/distribution_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 00</th>\n",
       "      <th>Topic 01</th>\n",
       "      <th>Topic 02</th>\n",
       "      <th>Topic 03</th>\n",
       "      <th>Topic 04</th>\n",
       "      <th>Topic 05</th>\n",
       "      <th>Topic 06</th>\n",
       "      <th>Topic 07</th>\n",
       "      <th>Topic 08</th>\n",
       "      <th>Topic 09</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic 54</th>\n",
       "      <th>Topic 55</th>\n",
       "      <th>Topic 56</th>\n",
       "      <th>Topic 57</th>\n",
       "      <th>Topic 58</th>\n",
       "      <th>Topic 59</th>\n",
       "      <th>Topic 60</th>\n",
       "      <th>Topic 61</th>\n",
       "      <th>Topic 62</th>\n",
       "      <th>Topic 63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01382</td>\n",
       "      <td>0.00617</td>\n",
       "      <td>0.08283</td>\n",
       "      <td>0.00738</td>\n",
       "      <td>0.05878</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00629</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00945</td>\n",
       "      <td>0.00714</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.17759</td>\n",
       "      <td>0.03436</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.07588</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.02693</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.03665</td>\n",
       "      <td>0.07053</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.02608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.08814</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00520</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic 00  Topic 01  Topic 02  Topic 03  Topic 04  Topic 05  Topic 06  \\\n",
       "0   0.01382   0.00617   0.08283   0.00738   0.05878   0.00009   0.00629   \n",
       "1   0.00022   0.00009   0.07588   0.00009   0.02693   0.00009   0.03665   \n",
       "\n",
       "   Topic 07  Topic 08  Topic 09    ...     Topic 54  Topic 55  Topic 56  \\\n",
       "0   0.00009   0.00009   0.00009    ...      0.00204   0.00009   0.00945   \n",
       "1   0.07053   0.00009   0.02608    ...      0.00009   0.00009   0.00009   \n",
       "\n",
       "   Topic 57  Topic 58  Topic 59  Topic 60  Topic 61  Topic 62  Topic 63  \n",
       "0   0.00714   0.00046   0.17759   0.03436   0.00034   0.00009   0.00009  \n",
       "1   0.00058   0.00082   0.08814   0.00070   0.00240   0.00520   0.00046  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dictionary of names mapped to their distributions for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = movies_df[\"original_title\"].values\n",
    "labels = {}\n",
    "for i in np.arange(len(distributions)):\n",
    "    labels[names[i]] = distributions.values[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Locality-Sensitive Hashing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create our distance class that NearPy uses for our locality-sensitive hashing. For our distance formula we will create the Jensen–Shannon divergence, as it is a reliable measure of comparing probability distributions. The reason will will be creating a distance class instead of just a function is because of the structure of NearPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class js(Distance):\n",
    "    def distance(self,p, q):\n",
    "        p = np.asarray(p)\n",
    "        q = np.asarray(q)\n",
    "       # normalize\n",
    "        p /= p.sum()\n",
    "        q /= q.sum()\n",
    "        m = (p + q) / 2\n",
    "        return (entropy(p, m) + entropy(q, m)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create the space that will store of our data, and as stated before we will be using Locality-sensitive hashing implemented through NearPy. We will set two important variables, the dimension of our space, and the number of bits for our hash. We will set the dimension to how many topics we have, 64, and we will want to set the bits to a low number since our dataset is not very big. If we deal with a very large dataset, then we can set a higher number of bits and the performance of getting a reccomendation we still be great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections\n",
    "\n",
    "# Dimension of our vector space\n",
    "dimension = 64\n",
    "bits_of_random_binary_hash = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we set our two variables, we will create a the random binary hash, as well as an Engine with pipeline configuration from NearPy, that will be organizing our storage space. The engine will also take in our distance formula as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp = RandomBinaryProjections('rbp', bits_of_random_binary_hash)\n",
    "\n",
    "engine = Engine(dimension, lshashes=[rbp],distance=js())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will want to give each row the name of the instance from before. Every row gets the title that relates to it, and this labeling is stored in a dictionary for fast retrieval. Then we will add each movies topic distribution and their label into our engine as vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = movies_df[\"original_title\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(len(distributions.values)):\n",
    "    v = distributions.values[i]\n",
    "    engine.store_vector(v, names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will retrieve our local topic model for faster predictions if a movie is not in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pystemmer in /anaconda3/lib/python3.6/site-packages (1.3.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pystemmer\n",
    "\n",
    "from bigml.topicmodel import TopicModel\n",
    "local_topic_model = TopicModel(topic_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a helper function that will be in our movie reccomemender function. Given a movie name and description, this function will get a topic distribution for the new movie from our local model, and add it into our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_movie(movie_name, description):\n",
    "    x=local_topic_model.distribution({\"original_title\": movie_name,\n",
    "                               \"description\": description})\n",
    "    new_distr = np.array([])\n",
    "    for item in x:\n",
    "        new_distr = np.append(new_distr, item[\"probability\"])\n",
    "    engine.store_vector(new_distr, movie_name)\n",
    "    labels[movie_name] = new_distr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Recommender Function\n",
    "This is our main function that will generate movie reccomendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommender(movie_name):\n",
    "    #checks if movie_name is in the database\n",
    "    if movie_name in labels:\n",
    "        \n",
    "        #if the movie_name is valid we use the engine.neighbors function to find similar movies\n",
    "        query = np.array(labels[movie_name])\n",
    "        ten_movies = engine.neighbours(query)\n",
    "        for ar in ten_movies:\n",
    "            print(ar[1])\n",
    "    else:\n",
    "        \n",
    "        #if the movie_name is not valid the function will ask the user to input an overview.\n",
    "        b = input(\"Sorry, that movie is not in the Database, please input the description: \")  \n",
    "        print()\n",
    "        #after retreiving the input we will add the new movie to the data base\n",
    "        add_movie(movie_name, b)\n",
    "        print()\n",
    "        #after adding the new movie we will call the movie_recommender function again\n",
    "        movie_recommender(movie_name)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the movie inputted exists in our database, then our function will output 10 closest neighbors in our defined space. The 10 neighbors will be the 10 movies that relate to each other through their descriptions. The top movie will be the original inputted movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Superman\n",
      "मिस्टर इंडिया\n",
      "Turbo Kid\n",
      "Atom Man vs Superman\n",
      "Batman Unlimited: Mechs vs. Mutants\n",
      "RoboCop 3\n",
      "Officer Downe\n",
      "Justice League: The New Frontier\n",
      "Dexter's Laboratory: Ego Trip\n",
      "ドラゴンボールZ たったひとりの最終決戦〜フリーザに挑んだZ戦士 孫悟空の父〜\n"
     ]
    }
   ],
   "source": [
    "movie_recommender(\"Superman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the movie does not exist in our database, the function will ask for for the description, add it to the database, and will out put 10 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, that movie is not in the Database, please input the description: A movie about a serial killer who comes to a town.\n",
      "\n",
      "\n",
      "The Scary Movie\n",
      "The Flesh and Blood Show\n",
      "Bram Stoker's Dracula\n",
      "Devil Dog: The Hound of Hell\n",
      "Children Shouldn't Play with Dead Things\n",
      "Ghost\n",
      "The Unholy\n",
      "パラノーマル・アクティビティ 第2章 TOKYO NIGHT\n",
      "Dèmoni\n",
      "Weirdsville\n"
     ]
    }
   ],
   "source": [
    "movie_recommender(\"The Scary Movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All BigML operations are drawn from the BigML API, and full documentation can be found at <a href=\"https://bigml.com/api\">BigML API Documentation</a>. This notebook used the API's python bindings, and full documentation can be found at <a href=\"https://bigml.readthedocs.io/en/latest/#\">BigML API Python Bindings</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
